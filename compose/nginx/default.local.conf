

events {
 worker_connections  1024;
}

http {
  gzip off;

  # need to setup external DNS resolver
  resolver 8.8.8.8;
  resolver_timeout 5s;

  # configure cache directory with 750G and holding old objects for max 30 days
  proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=default:500m max_size=750g inactive=30d;

  log_format rt_cache '$remote_addr - $upstream_cache_status "$host" [$time_local]  '
                      '"$request" $status $body_bytes_sent '
                      '"$http_referer" "$http_user_agent"';

  add_header X-Cache-Status $upstream_cache_status;

  server {
    listen 8080;

    access_log /var/log/nginx/access.log rt_cache;

    keepalive_timeout 3600;

    location / {
      proxy_http_version 1.1;

      set $s3_host 'aws-public-blockchain.s3.us-east-2.amazonaws.com';

      # Make sure we're proxying along the correct headers
      proxy_set_header Host $s3_host;
      # Pass along Authorization credentials to upstream S3
      proxy_set_header Authorization $http_authorization;
      # Make sure we're using Keep-Alives with S3
      proxy_set_header Connection '';

      # Configure out caches
      proxy_cache default;
      # Cache all 200 OK's for 30 days
      proxy_cache_valid 200 30d;
      # Use stale cache file in all errors from upstream if we can
      proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;
      # Lock the cache so that only one request can populate it at a time
      proxy_cache_lock on;

      # Verify and reuse our SSL session for our upstream connection
      proxy_ssl_verify on;
      proxy_ssl_session_reuse on;
      proxy_ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;

      # Set back a nice HTTP Header to indicate what the cache status was
      add_header X-Cache-Status $upstream_cache_status always;


      proxy_pass https://$s3_host;
    }
  }
}